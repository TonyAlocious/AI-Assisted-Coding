{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data Files with pandas\n",
    "\n",
    "There are three data files. Each file contains the reaction times (RTs) from 10 trials of a relatively simple task in which participants had to indicate which direction a briefly-presented arrow was pointing. The RTs are in seconds (s). Each file contains the RTs from a different participant. In each file there are three columns. You can determine what the columns are by looking at the first row (header) of each file.\n",
    "\n",
    "In this exercise, we will read in the data from the three files in the `data` directory: `s1.csv`, `s2.csv`, and `s3.csv`, and combine them into a single DataFrame. We will save that DataFrame, and then then calculate the mean RT for each participant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Data\n",
    "\n",
    "To start the process, I typed the first two lines of the prompt below:\n",
    "\n",
    "```python\n",
    "# read in three files from the data folder, whose names start with \"s\" and end in \"csv\"\n",
    "# concatenate them into one dataframe\n",
    "```\n",
    "\n",
    "After I hit `Enter`, Copilot suggested the third line of the prompt, which I accepted by hitting `Tab`:\n",
    "\n",
    "```python\n",
    "# write the result to a csv file\n",
    "```\n",
    "\n",
    "The cells below all reflect prompts written on the basis of the instructions above, and code generated entirely by Copilot. While your experience may be different, in writing this lesson we only had to type the first 2-line prompt, and Copilot generated not only the code but the other prompts/comments. \n",
    "\n",
    "However, you have to get used to the flow of working with Copilot. Copilot encourages a good coding style, and so it will sometimes only generate code if you hit `Enter` twice, so that there's an empty line between your prompt and the code. The same is true *after* a line of code: Copilot may force you to hit `Enter` twice before it generates the next prompt or line of code.\n",
    "\n",
    "After I typed the first two lines of the prompt below, and accepted the third line of the prompt (which was suggested by Copilot), I had to hit `Enter` twice to get the first line of code (`import pandas as pd`) generated.\n",
    "\n",
    "Although we intended to only read and combine the data files, after I typed the first two lines of the prompt and hit `Enter`, Copilot added a third suggested line to the prompt after I hit `Enter` the first time, which was to `write the dataframe to a csv file`. This is pretty cool, since that was also part of the instructions above! Is Copilot a mind-reader? No, it's just a very good predictor of what you might want to do next, based on the prompt you've written. It's a pretty common task in data science to read in a set of individual data files, concatenate them into a single DataFrame, and then save that DataFrame to a file for later use. So, Copilot is just doing what it's trained to do, which is to predict what you might want to do next, based on the prompt you've written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# read in three files from the data folder, whose names start with \"s\" and end in \"csv\"\n",
    "# concatenate them into one dataframe\n",
    "\n",
    "data_files = glob.glob('data/s*.csv')\n",
    "df = pd.concat((pd.read_csv(f) for f in data_files), ignore_index=True)\n",
    "\n",
    "# write the result to a csv file\n",
    "df.to_csv('data/combined_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code ran without errors, but we didn't ask for any output. Next we'll to some checks to confirm that the code ran correctly, as described in the instructions. We'll start by checking the number of columns in the DataFrame. As noted above, there should be three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "participantID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trial",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "RT",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "39104a98-6e8b-42b6-bd7b-9bd61b364df6",
       "rows": [
        [
         "0",
         "s2",
         "1",
         "0.433093893"
        ],
        [
         "1",
         "s2",
         "2",
         "0.392526034"
        ],
        [
         "2",
         "s2",
         "3",
         "0.396830804"
        ],
        [
         "3",
         "s2",
         "4",
         "0.417987737"
        ],
        [
         "4",
         "s2",
         "5",
         "0.371810078"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participantID</th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.392526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.396831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.417988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.371810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participantID  trial        RT\n",
       "0            s2      1  0.433094\n",
       "1            s2      2  0.392526\n",
       "2            s2      3  0.396831\n",
       "3            s2      4  0.417988\n",
       "4            s2      5  0.371810"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# show the first5 5 rows of the data frame\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the DataFrame has 3 columns, as expected. Next, we'll check that we get the expected number of rows (30) and columns (3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that we have the epxected numebrs of rows(30) and columns(3)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also were instructed to raise an error message if the number of rows or columns is incorrect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise an error message if number of rows is not 30 or number of columns is not 3\n",
    "# make the if statement more pythonic by combining the two conditions into one\n",
    "#if df.shape[0] != 30 or df.shape[1] != 3:\n",
    "if df.shape != (30, 3):\n",
    "    raise ValueError('Dataframe does not have the expected shape of (30, 3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Your Test\n",
    "This generates no output. This is a Good Thing, because it means that the number of rows and columns is correct. However, it's a bit dangerous to assume no news is good news, because no news could also mean your code is not working. So, we should test that the error message is generated if we change the expected number of rows or columns.\n",
    "\n",
    "We don't want to actually remove any rows from the DataFrame, but we can use **slicing** to create a view of the DataFrame that has fewer rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1809890142.py, line 5)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31massert df_slice.shape == (10, 3): pass\u001b[39m\n                                    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# create a slice of df with only 10 rows\n",
    "df_slice = df.iloc[:10, :]\n",
    "print(df_slice.shape)\n",
    "# now same if statement on df_slice\n",
    "# assert df_slice.shape == (10, 3)\n",
    "if df_slice.shape != (30, 3):\n",
    "    raise ValueError('Dataframe slice does not have the expected shape of (30, 3)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get an `AssertionError`, which is a Good Thing because it confirms that our error-checking code is working. We can do the same thing to test the error-checking code for the number of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dataframe slice does not have the expected shape of (30, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# same if statement on df_slice\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_slice.shape != (\u001b[32m30\u001b[39m, \u001b[32m3\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mDataframe slice does not have the expected shape of (30, 3)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Dataframe slice does not have the expected shape of (30, 3)"
     ]
    }
   ],
   "source": [
    "df_slice = df.iloc[:, :2]\n",
    "# same if statement on df_slice\n",
    "if df_slice.shape != (30, 3):\n",
    "    raise ValueError('Dataframe slice does not have the expected shape of (30, 3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yes, our code will throw errors if the number of rows or columns is incorrect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Mean RT for Each Participant... and Our First Bug\n",
    "Our next instruction is to calculate the mean RT for each participant. Let's prompt Copilot to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participantID\n",
      "s1    0.389548\n",
      "s2    0.444785\n",
      "s3    0.446009\n",
      "Name: RT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# calculate mean rt for each participant\n",
    "mean_rt = df.groupby('participantID')['RT'].mean()\n",
    "# print(df.groupby('participantID').mean())\n",
    "print(mean_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "participantID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trial",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "RT",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a5684c9f-6f10-490d-8b89-25f43b9aeb81",
       "rows": [
        [
         "6",
         "s2",
         "7",
         "0.411051235"
        ],
        [
         "5",
         "s2",
         "6",
         "0.659228422"
        ],
        [
         "24",
         "s1",
         "5",
         "0.437764713"
        ],
        [
         "3",
         "s2",
         "4",
         "0.417987737"
        ],
        [
         "26",
         "s1",
         "7",
         "0.400544278"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participantID</th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.411051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.659228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>s1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.437765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.417988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>s1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.400544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participantID  trial        RT\n",
       "6             s2      7  0.411051\n",
       "5             s2      6  0.659228\n",
       "24            s1      5  0.437765\n",
       "3             s2      4  0.417988\n",
       "26            s1      7  0.400544"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Debugging Copilot-Generated Code\n",
    "\n",
    "Typically, when you get a long, scary error message like the one above, you can ignore a lof of what is in the middle. The most important parts are the last line, which tells you what the error is, and the first lines, which usually indicate what line in the code you tried to run caused the error. What's in between is the *stack trace*, which is a list of all the functions that were called in the process of trying to run the code. But most of the time, the error is a result of the code you wrote (the first lines), not the code in the underlying Python functions that your code called (the middle lines).\n",
    "\n",
    "In this case, we see a `KeyError: 'participant'` at the bottom of the error message. Recall that Python dictionaries are sets of **key**-value pairs. The keys are the names of the columns, and the values are the data in those columns. \n",
    "\n",
    "You can think of a pandas DataFrame as a dictionary in which the column names are keys, and the values in that column are its values. This is a common way that pandas functions refer to column names and their values. So the error message above indicates that the code tried to access a column called `subject` in the DataFrame, but that column doesn't exist. We can see at the top of the error message that the code that caused the error is: `---> 2 df.groupby('participant').mean()`. This means it's line 2 of the cell above that caused the error. \n",
    "\n",
    "As a novice coder, however, you might not know or remember that pandas DataFrames represent column names and data as dictionary key-value pairs. If you don't understand what an error means, you can use Copilot to help you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Copilot to Explain Errors and Suggest Fixes\n",
    "\n",
    "Somewhat counterintuitively, even though Copilot can generate code with bugs, it can also provide feedback on errors in the code it generated. \n",
    "\n",
    "Copilot has a few features that can help you diagnose and fix your code. The one we have found most effective is Copilot Chat. For this reason, we won't describe other methods, such as Copilot's \"Fix\" feature, which is described in the [Copilot documentation](https://copilot.github.com/#/guide)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![](images/chat_icon.png)  Copilot Chat\n",
    "\n",
    " Another, really useful option is the `Chat` option, which you can option by clicking the `Chat` icon (shown above) in the Activity Bar (left side of VS Code). This allows you to have a conversation with Copilot about what you want to do. If you've used [Chat-GPT](https://chat.openai.com/) before, this will be familiar to you as it's essentially the same type of natural-language interface.\n",
    "\n",
    "There are different approaches to using Copilot Chat to help fix an error. One is to click in the cell that generates the error, and then click in the Copilot Chat input box, and typing: \n",
    "\n",
    "```\n",
    "the selected cell generates an error. how can i fix this error?\n",
    "``` \n",
    "\n",
    "In response to this prompt for the present error, I got the following response:\n",
    "\n",
    ">If you are getting an error with the selected cell, there could be a few reasons why. Here are some possible solutions:\n",
    ">\n",
    ">1. Check that the 'participant' column is present in the dataframe. You can do this by printing out the dataframe using the `print()` function and checking that the 'participant' column is present.\n",
    ">\n",
    ">2. Check that the 'participant' column is spelled correctly. If the column is misspelled, you will get a \"KeyError\" when trying to group by that column.\n",
    ">\n",
    ">3. Check that the 'participant' column is of the correct data type. If the 'participant' column is not a string or categorical data type, you may need to convert it using the `astype()` method.\n",
    ">\n",
    ">4. Check that the dataframe contains numerical columns. If the dataframe only contains non-numerical columns, you will get a \"DataError\" when trying to calculate the mean.\n",
    ">\n",
    ">5. Check that the dataframe does not contain missing values. If the dataframe contains missing values, you may need to remove them using the `dropna()` method before calculating the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Error with Copilot's Help\n",
    "\n",
    "These are actually really good responses, and they are provided in a logical order to go through in debugging. We could work through them in order, but — spoiler alert — the first suggestion actually leads to a solution. \n",
    "\n",
    "### Check that the 'participant' Column is Present in the DataFrame\n",
    "The first thing to do is to check that the column exists, and is spelled correctly. So let's start with that. Do you remember how to check the names of the columns in a pandas DataFrame? If not, you can write a Copilot prompt to help you out. In the cell below, write a prompt that will print the names of the columns in the DataFrame. Then run the cell, and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['participantID', 'trial', 'RT'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the names of the columns in df\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to look at the first few rows of the DataFrame, which includes the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "participantID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trial",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "RT",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "21f848c3-851a-41d4-ac90-ee7d3a2035bd",
       "rows": [
        [
         "0",
         "s2",
         "1",
         "0.433093893"
        ],
        [
         "1",
         "s2",
         "2",
         "0.392526034"
        ],
        [
         "2",
         "s2",
         "3",
         "0.396830804"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participantID</th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.392526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.396831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participantID  trial        RT\n",
       "0            s2      1  0.433094\n",
       "1            s2      2  0.392526\n",
       "2            s2      3  0.396831"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first 3 rows of the dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A third option, when using Jupyter notebooks with VS Code, is to click on the `Variables` button in the toolbar at the top of the notebook window. This will pop up a variable viewer in sub-window below your notebook. You can click on the variable names to see their values. For DataFrames, it actually shows a list of the columns in the window, and you can double-click on the variable name to see the contents of the DataFrame in another window, the **Data Viewer**. This view is similar to a spreadsheet. In fact, you can directly edit values in the Data Viewer. *You should never directly edit values like this*, however. Any steps you do manually are not documented in your code, and are not reproducible.  \n",
    "\n",
    "The screenshot below shows the variables and Data Viewer for the current context.\n",
    "\n",
    "![](images/inspectors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Solution\n",
    "\n",
    "Using any of the three approaches above, when we look at the column names, we see that they are `participantID`, `trial`, and `RT`. The code that generated the error was trying to access a column called `participant`, which doesn't exist. It should be `participantID`. So we need to change the code to access the correct column name. Or, engineer our prompt to do so.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "This is an important lesson on prompt engineering. You're more likely to get working code if you use the actual variable names in the prompt, rather than expecting Copilot to make inferences about what variable you're referring to based on the context.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "participantID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trial",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RT",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9b937c36-44be-4c6b-9456-725ce4c1b73f",
       "rows": [
        [
         "s1",
         "5.5",
         "0.3895479033"
        ],
        [
         "s2",
         "5.5",
         "0.44478485809999996"
        ],
        [
         "s3",
         "5.5",
         "0.4460092835"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participantID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.389548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.444785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.446009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               trial        RT\n",
       "participantID                 \n",
       "s1               5.5  0.389548\n",
       "s2               5.5  0.444785\n",
       "s3               5.5  0.446009"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- IGNORE ---\n",
    "# find mean for each column grouped by participantID\n",
    "df.groupby('participantID').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, however the code is providing means for both columns in the DataFrame (`trial` and `RT`), not just for `RT` (sometimes the same prompt actually does select only `RT` but we'll explore when it doesn't). We can add to our prompt to tell it not to include `trial` in the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "participantID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RT",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c7a7c176-b5d8-4711-9053-85a084acb120",
       "rows": [
        [
         "s1",
         "0.3895479033"
        ],
        [
         "s2",
         "0.44478485809999996"
        ],
        [
         "s3",
         "0.4460092835"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participantID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>0.389548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>0.444785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>0.446009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RT\n",
       "participantID          \n",
       "s1             0.389548\n",
       "s2             0.444785\n",
       "s3             0.446009"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don;t include trial number in the mean calculation\n",
    "df.groupby('participantID')[['RT']].mean()\n",
    "# but make the code so that it is directly dropping trial number column\n",
    "df.groupby('participantID').mean().drop(columns=['trial'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above generated code does what we want. However, from the perspectives of coding style and efficiency, it's not optimal. Python executes this **chained command** from left to right. So, it first computes the mean for each column in the DataFrame, and then drops the column `trial`.\n",
    "\n",
    "It seems unnecessary to compute the mean for `trial` and then drop it. This isn't really Copilot's fault — we did explicitly tell it not to show the mean for trial, but it's not smart enough to know that we don't want to compute it in the first place; it seems to have interpreted our prompt as a literal sequence of commands.\n",
    "\n",
    "We can modify the prompt in a way that generates more efficient code, by being specific about the column that we do want, rather than what we don't want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Boolean index has wrong length: 3 instead of 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# don't include trial number in the calculation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mparticipantID\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrial\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# no ignore the trial number completely\u001b[39;00m\n\u001b[32m      4\u001b[39m df.loc[:, df.columns != \u001b[33m'\u001b[39m\u001b[33mtrial\u001b[39m\u001b[33m'\u001b[39m].groupby(\u001b[33m'\u001b[39m\u001b[33mparticipantID\u001b[39m\u001b[33m'\u001b[39m).mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/neural_data_science/lib/python3.12/site-packages/pandas/core/indexing.py:1185\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_scalar_access(key):\n\u001b[32m   1184\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._get_value(*key, takeable=\u001b[38;5;28mself\u001b[39m._takeable)\n\u001b[32m-> \u001b[39m\u001b[32m1185\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1187\u001b[39m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[32m   1188\u001b[39m     axis = \u001b[38;5;28mself\u001b[39m.axis \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/neural_data_science/lib/python3.12/site-packages/pandas/core/indexing.py:1378\u001b[39m, in \u001b[36m_LocIndexer._getitem_tuple\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._multi_take_opportunity(tup):\n\u001b[32m   1376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._multi_take(tup)\n\u001b[32m-> \u001b[39m\u001b[32m1378\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/neural_data_science/lib/python3.12/site-packages/pandas/core/indexing.py:1021\u001b[39m, in \u001b[36m_LocationIndexer._getitem_tuple_same_dim\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1018\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m com.is_null_slice(key):\n\u001b[32m   1019\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m retval = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[32m   1023\u001b[39m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m retval.ndim == \u001b[38;5;28mself\u001b[39m.ndim\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/neural_data_science/lib/python3.12/site-packages/pandas/core/indexing.py:1414\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1412\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_slice_axis(key, axis=axis)\n\u001b[32m   1413\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m com.is_bool_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m1414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[32m   1416\u001b[39m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/neural_data_science/lib/python3.12/site-packages/pandas/core/indexing.py:1210\u001b[39m, in \u001b[36m_LocationIndexer._getbool_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1206\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   1207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getbool_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, axis: AxisInt):\n\u001b[32m   1208\u001b[39m     \u001b[38;5;66;03m# caller is responsible for ensuring non-None axis\u001b[39;00m\n\u001b[32m   1209\u001b[39m     labels = \u001b[38;5;28mself\u001b[39m.obj._get_axis(axis)\n\u001b[32m-> \u001b[39m\u001b[32m1210\u001b[39m     key = \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1211\u001b[39m     inds = key.nonzero()[\u001b[32m0\u001b[39m]\n\u001b[32m   1212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._take_with_is_copy(inds, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/neural_data_science/lib/python3.12/site-packages/pandas/core/indexing.py:2717\u001b[39m, in \u001b[36mcheck_bool_indexer\u001b[39m\u001b[34m(index, key)\u001b[39m\n\u001b[32m   2713\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_like(result):\n\u001b[32m   2714\u001b[39m     \u001b[38;5;66;03m# GH 33924\u001b[39;00m\n\u001b[32m   2715\u001b[39m     \u001b[38;5;66;03m# key may contain nan elements, check_array_indexer needs bool array\u001b[39;00m\n\u001b[32m   2716\u001b[39m     result = pd_array(result, dtype=\u001b[38;5;28mbool\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2717\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_array_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/neural_data_science/lib/python3.12/site-packages/pandas/core/indexers/utils.py:539\u001b[39m, in \u001b[36mcheck_array_indexer\u001b[39m\u001b[34m(array, indexer)\u001b[39m\n\u001b[32m    537\u001b[39m     \u001b[38;5;66;03m# GH26658\u001b[39;00m\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer) != \u001b[38;5;28mlen\u001b[39m(array):\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[32m    540\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBoolean index has wrong length: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    541\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(indexer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(array)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    542\u001b[39m         )\n\u001b[32m    543\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_integer_dtype(dtype):\n\u001b[32m    544\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mIndexError\u001b[39m: Boolean index has wrong length: 3 instead of 2"
     ]
    }
   ],
   "source": [
    "# don't include trial number in the calculation\n",
    "df.groupby('participantID').mean().loc[:, df.columns != 'trial']\n",
    "# no ignore the trial number completely\n",
    "df.loc[:, df.columns != 'trial'].groupby('participantID').mean()\n",
    "# no looking for something like df.groupby('participantID')[['RT']].mean()\n",
    "# code:\n",
    "df.groupby('participantID')['RT'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By way of showing how sensitive Copilot is to the structure of your prompt, a slightly different (and arguably more logical) phrasing of the prompt above generates the less-efficient code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "participantID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RT",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7e6f963e-b006-4942-8264-d1b49f2836cf",
       "rows": [
        [
         "s1",
         "0.3895479033"
        ],
        [
         "s2",
         "0.44478485809999996"
        ],
        [
         "s3",
         "0.4460092835"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "participantID\n",
       "s1    0.389548\n",
       "s2    0.444785\n",
       "s3    0.446009\n",
       "Name: RT, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('participantID')['RT'].mean()\n",
    "# do not compute mean for trial RT and then drop it though, give the new code\n",
    "df.groupby('participantID')['RT'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "One thing you may notice is that the result of the last command above is nicely-formatted when it is displayed, whereas the one before it is in a more \"raw\" format. This is not really important here, but it's worth understanding why the difference occurs. When you call a pandas DataFrame it prints in a nicely formatted output. However, when you call a pandas Series (which is a single column), it prints in a more detailed but less \"pretty\" way. \n",
    "\n",
    "In the output immediately above, the code created a DataFrame with two columns (`trial` and `RT`) and then dropped the `trial` column, but as such it remained a DataFrame and so was nicely formatted.\n",
    "\n",
    "In contrast, the output of using the `mean()` method on a single column (`RT`) in the cell above that is a Series.  \n",
    "<p><p>\n",
    "We'll worry about the formatting later, but it's good to understand why it happens because the distinction between DataFrames and Series often causes confusion and errors if it's not understood.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
